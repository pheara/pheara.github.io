<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:title" content="Beyond the Trolley Problem &middot; Pheara’s Ramblings ">
        <meta property="og:site_name" content="Pheara’s Ramblings"/>
        <meta property="og:description" content="A collection of ideas, designs and essays created over the course Pheara&#39;s Media and Human Centered Computing Studies">
        <meta property="og:url" content="https://pheara.github.io/article/beyond-the-trolley-problem/" />
        <meta property="og:locale" content="en-US">
        <meta name="author" content="Pheara">
        <meta name="description" content="A collection of ideas, designs and essays created over the course Pheara&#39;s Media and Human Centered Computing Studies">
        <meta name="keywords" content="game design, sociology of technology, human computer interaction, pheara">
        <meta name="generator" content="Hugo 0.63.0-DEV" />
        <link rel="icon" href="https://pheara.github.io/assets/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="https://pheara.github.io/css/slender-base.css">
        <link rel="stylesheet" href="https://pheara.github.io/css/slender-color-schemes.css">
        <link rel="stylesheet" href="https://pheara.github.io/assets/icons/sprite.css">
        <link rel="stylesheet" href="https://pheara.github.io/css/font-awesome-4.5.0.min.css">
        <link rel="stylesheet" href="https://pheara.github.io/css/highlight-9.0.0-default.min.css">
        <title>
            
                Beyond the Trolley Problem &middot; Pheara’s Ramblings
            
        </title>
    </head>
    <body class="color-scheme-white">
        <div class="container">
            <header>
                <nav>
                    <ul><li><a href="https://pheara.github.io/about/">about</a></li><li><a href="https://pheara.github.io/">home</a></li></ul>
                </nav>
                
                    <h1 class="post-title">Beyond the Trolley Problem</h1>
                    <aside>
                          
                        <span>
                          on
                          <strong>Mon, Jul 15, 2019</strong>
                        </span>
                        
                        <span>
                          |
                          Tagged:
                        </span>
                        <ul class="tags">
                          
                            <li><a href="/tags/ethics">ethics</a> </li>
                          
                        </ul>
                        
                
            </header>

<article class="article-content">
    <p>In the recently published &ldquo;Trolled by the Trolley
Problem&rdquo;[<a href="#ref-MirnigTrolledTrolleyProblem2019">1</a>]
Alexander G. Mirnig and Alexander Meschtscherjakov point out the severe
limitations of the trolley problem with regard to ethics- and technology
assessment as applied to (semi-)autonomous vehicles. They go on to
criticize the amount of effort spent on it and argue for better foci. In
this essay, I'll give a short overview over their critique and want to
point out other, wider potential issues in need of studying and societal
deliberation beyond the artificial, construed confines of the trolley
problem.</p>
<h2 id="limitations-of-the-trolley-problem">Limitations of the Trolley Problem</h2>
<p>As laid out by Mirnig and Meschtscherjakov, the trolley problem (see
fig. 1) is intended to make a point regarding ethics theory and
specifically designed to be unsolvable. <em>Deontological</em>, i.e.
rule-based, ethics-frameworks usually hold a rule that forbids killing
another human being. The trolley-problem presents a situation where
breaking that rule seems to align better with one's moral sense, thus
making an argument for <em>consequentialist utilitarian</em> (i.e.
outcome-focused and value-function based) ethics, where lives are
compared numerically. It was never intended as a benchmark to be applied
to the design of artificial moral agents, as in the case of autonomous
vehicles.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><em>Figure 1: The classical trolley problem: the actor can pull the lever to
save five people on the upper track from the out-of-control tram,
condemning the person on the lower track to die. Image CC BY-SA 4.0
<a href="https://commons.wikimedia.org/wiki/User:McGeddon">McGeddon @ Wikipedia</a></em></p>
<!-- raw HTML omitted -->
<p>In particular, Mirning and Meschtscherjakov argue, that the vast
majority of situations encountered on the road are <em>epistemological
dilemmas</em>, i.e. where the problem lies in incomplete knowledge and given
more knowledge the dilemmas could be resolved. As such they argue that
an improvement of sensor-technology and inter-vehicle-communication in
itself helps autonomous vehicles to act more ethically, e.g. preventing
crashes like the one in Williston, Florida, where a Tesla Model S failed
to detect a white tractor-trailer against the sky
[<a href="#ref-YadronTesladriverdies2016">2</a>].</p>
<p>Even where only actual <em>ontological dilemma</em>-situations are considered,
i.e. ones wherein all knowledge is available but the situation still
presents itself as a moral dilemma, trolley-problems have several
inherent flaws and in general don't represent day-to-day road situations
at all. Regarding the inherent flaws, usual ethic-theoretical arguments
against trolley problems are, e.g. that they conflict with <em>deontic
consistency</em>, i.e. that situations can't both mandate and forbid some
action at the same time. Another argument is, that even from a
deontological/rule-based perspective the options are <em>not symmetrical</em>
and one of the options represents more rule-violations or a more severe
one. For situations that truly were symmetrical, the choice wouldn't
matter.</p>
<p>But the most striking critique, in my opinion, is that the trolley
problem is stated without context, without a description of how this
situation came about. Taking it into account allows studying these
situations from an <em>intentionalist</em> perspective. In this perspective, an
agent with the intention to save lives would be ethical. But even from a
<em>consequentialist</em> (i.e. outcome-oriented) perspective, this added
context allows &ldquo;solving&rdquo; the dilemma but placing the burden with the
agent responsible for bringing about the situation in the first place.
This puts the focus on <em>avoiding</em> trolley-problem-like situations (by
improving sensors, communication and decision-making algorithms through
transparency, scrutiny, and review).</p>
<p>Regarding this shift of focus to the situations preceding
trolley-problem-situations, Mirning and Meschtscherjakov argue that in
front of court a human driver would be interviewed whether they were
intoxicated or not, if they had a valid driving license and how the
situation came about, not what the exact split-second decision-process
was in the last moment before the crash. Thus, they continue, the same
measure should apply to artificial agents. Media coverage
[<a href="#ref-YadronTesladriverdies2016">2</a>,
<a href="#ref-LevinSelfdrivingUberkills2018">3</a>] and public
outcry following the first fatalities
[<a href="#ref-Listselfdrivingcar2019">4</a>] involving
(semi-)automated cars, raise doubt that this will happen, however. Even
though a common hope is that self-driving cars will have a lower
accident rate than human-driven ones, these first fatalities and the
surrounding discussion might and assign autonomous vehicles a symbolic
meaning of &ldquo;calculating killer cars&rdquo;. In this sense, Mirnig and
Meschtscherjakov point out that &ldquo;trolley dilemmas highlight a potential
authority of machines over human life that society is uncomfortable
with.</p>
<h2 id="whose-ethics">Whose Ethics</h2>
<p>What the trolley problem is helpful for, however, is pointing out that
there are no universal moral principles to be followed. In the same
vein, one might argue, that there's no universal, utilitarian
value-function. The famous &ldquo;Moral Machine
Experiment&rdquo;[<a href="#ref-AwadMoralMachineexperiment2018">5</a>]
highlights this and amongst others shows how people with different
cultural backgrounds would decide in auto-generated, wild variations of
the trolley problem (e.g. &ldquo;two men and one female athlete versus two
large men and one large woman&rdquo;). For instance, people from countries in
the &ldquo;Southern&rdquo; group (assigned according to the Inglehart–Welzel
Cultural Map
2010–2014[<a href="#ref-InglehartModernizationculturalchange2005">6</a>])
chose the lives of higher-status persons, women and children more often
(compared to other factors) than people from countries in the &ldquo;Western&rdquo;
group.</p>
<p>This debunking of any notions of universalism and moral realism opens a
discussion of whose ethics a (semi-)autonomous car should follow and
which moral design decisions were made by those who construct it.</p>
<p>For instance, one might argue, that the human driver is the ultimate
moral authority in (semi-)autonomous driving and legally fully
responsible. For one this would require having some sort of system, that
gets initialized with the human agent's personal utility function, or
moral codes or virtue system whenever they get into the car. This would
also require making these entirely encodable or risk introducing bias
through what the system can internally represent and what it can't.
Also, especially in semi-autonomous but to a lesser degree also in
autonomous vehicles, the decision-making process needs to be transparent
to the driver/user of the vehicle, if they're the ones to hold the
responsibility.</p>
<h2 id="bias">Bias</h2>
<p>Assuming that this process of customization will not exist or will be
less than total, we can argue that more or less hidden biases will exist
in this technology. Most of it is developed primarily in and for the
&ldquo;western&rdquo; nations &ndash; of the recent KPMG Autonomous Vehicle Readiness
Index report [<a href="#ref-ThrelfallAutonomousVehiclesReadiness2018">7</a>,
<a href="#ref-McCarthyCountriesBestPrepared">8</a>] 7 of the first
10 and 13 of the first 20 nations were counted to the &ldquo;Western&rdquo; group by
the authors of &ldquo;The Moral Machine
experiment[<a href="#ref-AwadMoralMachineexperiment2018">5</a>]. As
&ldquo;code is law&rdquo; [<a href="#ref-LessigCodelaw1999">9</a>] the moral
frameworks and laws of these technology-driving nations is imposed on
other cultures, with potentially radically different frameworks. This
makes the technology less useful for already economically disadvantaged
nations (e.g. the &ldquo;Global South&rdquo;) and directly threatens to supplant
their moral codes, virtues, and values in this context. Especially given
the historic relationship of colonialism and (neo-)imperialism this
seems particularly objectable. An example from a different type of
algorithmic system would be how social media censors of US-owned social
networks censor according to US-American values (e.g. &ldquo;hate speech is
free speech&rdquo; but too much skin or anything related to menstruation is
reprehensible) instead of local ones.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><em>Figure 2: Google's self-driving car (CC-BY-NC-SA Willy Volk @ flickr)</em></p>
<!-- raw HTML omitted -->
<p>Regarding the basic usefulness, biases might also and especially come in
the form of which environments autonomous vehicles are tested in and
thus will perform well. Currently, fully autonomous cars seem to be
mostly tested in Silicon Valley (and similar regions) on traffic-light
roads (e.g. fig. 2) and thus will very likely struggle in areas without
roads or traffic that looks and acts substantially different (e.g.
fig. 3), as previously unknown problems arise and hidden assumptions
rear their head. To counteract these biases, as with other algorithmic
systems, diverse teams and an inclusive design and testing process are
necessary, as well as transparency of algorithms, to allow for external
scrutiny. Additionally, very likely legislation and institutionalized
accident assessment will be necessary to regulate in the interests of
the people, as self-regulation of algorithm-producing corporations has
shown to be ineffective as e.g. shown by repeated scandals around
Facebook and in particular Uber, that builds its business model on
exploiting legal loop-holes or straight-out breaking the law
[<a href="#ref-LeeUberhassecret2017">10</a>].</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><em>Figure 3: Traffic in Vietnam (CC-BY-NC-ND Eric Havir @ flickr)</em></p>
<!-- raw HTML omitted -->
<h2 id="fairness">Fairness</h2>
<p>Beyond purely algorithm-related issues, there are several other issues
surrounding self-driving cars, that will need addressing, for them to be
at least not detrimental to the broader public and humanity as a whole
and ideally beneficial.</p>
<p>For one, driving is one of the most common occupations. In the US, as
2014 census data shows, an average of 3% of the over 16-year olds (i.e.
4.4 million persons) are working as
drivers[<a href="#ref-FaheyDriverlesscarswill2016">11</a>]. For some
regions this statistic is even higher, going up to 9%. The most common
among these occupations is truck driving, a field where the push to
automation is strong, with the first step being platooning systems that
link trucks driving behind each other together, with only the lead truck
being controlled by a human. These jobs will be lost, and very likely
not many of the affected persons will find employment in the new, more
engineering-oriented and academic occupations surrounding these systems.
Also, in the run-up to full-automation ever-increasing work-place
surveillance is being forced on these drivers
[<a href="#ref-VoxHowjobsurveillance2017">12</a>].</p>
<p>As another socio-economic factor, most self-driving cars are massively
expensive at the moment (e.g. the Tesla cars). Even if this
wealth-caused access-gap closes eventually, adoption will start with
wealthier persons. Any changes made to the public environments will
further disadvantage already marginalized persons. E.g. some realization
concepts for a widespread adoption suggest lanes reserved for
self-driving cars to reduce risks of accidents when interacting with
human-driven vehicles. Introducing this and other concepts primarily
benefit those who can afford and chose to own autonomous cars at the
disadvantage of everybody else. This wouldn't be a new trend/relation,
however, as the same holds for human-driven cars towards everyone else,
given societies prioritization of car traffic in the last century, that
is only slowly being reversed in some places. People who can't afford or
chose not drive cars feel the full effect of the pollution caused by
them and lose (traffic) space, that could be used for public transport,
bike lanes, pedestrian zones, parks, etc. Especially in rural areas
where public transport is continuously reduced in favor of roads for car
traffic, not being able to afford one makes one's life severely harder.
Depending on how we as a society decide to use the self-driving car
technology it might further strengthen these effects or help alleviate
the problems by e.g. being available as a cheap, on-demand public
transport and/or car-sharing system, that gives people mobility who
couldn't drive a non-autonomous car (e.g. due to age, disabilities,
etc).</p>
<h2 id="summary">Summary</h2>
<p>Summarizing, it can be said that despite the trolley problem's
prominence it is badly suited for ethics discussions surrounding
self-driving cars and generally a bad benchmark for those algorithms&rsquo;
performance. It highlights, however, a need for algorithmic transparency
and increased facilities to prevent situations such as these from coming
about in practice. Additionally, in its original purpose points out that
there is no such thing as a universal moral system, raising the question
of whose moral judgment the vehicles will follow. In this sense, looking
beyond the trolley problem, a plethora of issues of and around
self-driving cars present themselves, that require addressing for this
new technology to be widely beneficial. These include issues of
&ldquo;West&rdquo;-centrism, (algorithmic) bias, potentially deepening
socio-economic divides, as well as a threat to a large number of
people's jobs and thus livelihood. By deliberating how we as a society
want to engineer, regulate and most of all use this new technology, it
bears a promise of great benefit for all but also, great harm for
(already) marginalized people.</p>
<h2 id="references">References</h2>
<!-- raw HTML omitted -->
</article>
        </div>
        
        <script src="https://pheara.github.io/js/highlight-9.0.0.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        
    </body>
</html>
